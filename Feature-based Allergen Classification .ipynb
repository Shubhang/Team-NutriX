{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Goal\nThe goal is to make a simple model that can go from an image (taken with a smartphone) to a prediction of how likely different allergens are to be present in the food. It could be part of a helpful app for people trying to avoid foods they might be allergic to.\n\n## Setup\nWe basically take the precomputed color features and build simple models in order to determine if the food contains any of the 8 different allergens identified [here](https://www.kaggle.com/kmader/ingredients-to-allergies-mapping/). We try to create a balanced training group and a realistic validation group to know if the model is learning anything useful","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.rcParams[\"figure.figsize\"] = (15, 10)\nplt.rcParams[\"figure.dpi\"] = 125\nplt.rcParams[\"font.size\"] = 14\nplt.rcParams['font.family'] = ['sans-serif']\nplt.rcParams['font.sans-serif'] = ['DejaVu Sans']\nplt.style.use('ggplot')\nsns.set_style(\"whitegrid\", {'axes.grid': False})\nplt.rcParams['image.cmap'] = 'gray' # grayscale looks better","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"from pathlib import Path\nimport numpy as np\nimport pandas as pd\nimport os\nfrom skimage.io import imread as imread\nfrom skimage.util import montage\nfrom PIL import Image\nmontage_rgb = lambda x: np.stack([montage(x[:, :, :, i]) for i in range(x.shape[3])], -1)\nfrom skimage.color import label2rgb\nimage_dir = Path('..') / 'input' / 'minigredients'\nmapping_file = Path('..') / 'input' / 'ingredients-to-allergies-mapping' / 'clean_list.json'\nalleg_df = pd.read_json(mapping_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alleg_df['image_path'] = alleg_df['image_path'].map(lambda x: image_dir / 'subset' / x) \nprint(alleg_df['image_path'].map(lambda x: x.exists()).value_counts())\nallergens = alleg_df.columns[3:].tolist()\nalleg_df.sample(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read in the Color Features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"color_file = Path('..') / 'input' /  'images-to-features' / 'color_features.json'\ncolor_feat_df = pd.read_json(color_file)\ncolor_feat_df['image_path'] = color_feat_df['image_path'].map(lambda x: image_dir / 'subset' / x) \n\ncolor_feat_dict = {c_row['image_path']: c_row['color_features'] for _, c_row in color_feat_df.iterrows()}\n# add a new color feature column\nalleg_df['color_features'] = alleg_df['image_path'].map(color_feat_dict.get)\nalleg_df.sample(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Correlations between allergens\nHere we can see which ones show up together. Most are expected like eggs and milk being together but interestingly tree-nuts have a negative (weak) correlation with peanuts.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"co_all = np.corrcoef(np.stack(alleg_df[allergens].applymap(lambda x: 1 if x>0 else 0).values, 0).T)\nfig, ax1 = plt.subplots(1, 1, figsize=(10, 10))\nsns.heatmap(co_all, annot=True, fmt='2.1%', ax=ax1, cmap='RdBu', vmin=-1, vmax=1)\nax1.set_xticklabels(allergens, rotation=90)\nax1.set_yticklabels(allergens);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# package the allergens together\nalleg_df['allergy_vec'] = alleg_df[allergens].applymap(lambda x: 1 if x>0 else 0).values.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split up the groups so we can validate our model on something besides the direct training data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(alleg_df.drop('ingredients_list', 1), \n                 test_size = 0.2, \n                 random_state=2019,\n                  # hack to make stratification work                  \n                 stratify = alleg_df['allergy_vec'].map(lambda x: x[0:3]))\ntrain_df.reset_index(inplace=True)\nvalid_df.reset_index(inplace=True)\nprint(train_df.shape[0], 'training images')\nprint(valid_df.shape[0], 'validation images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x_vec = np.stack(train_df['color_features'].values, 0)\ntrain_y_vec = np.stack(train_df['allergy_vec'], 0)\nprint(train_x_vec.shape, '->', train_y_vec.shape)\nvalid_x_vec = np.stack(valid_df['color_features'].values, 0)\nvalid_y_vec = np.stack(valid_df['allergy_vec'], 0)\nprint(valid_x_vec.shape, '->', valid_y_vec.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Display Results Nicely\nWe want to have code to display our results nicely so we can see what worked well and what didn't","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score\ndef show_model_results(in_model, use_split='valid', plot_type='swarm'):\n    if use_split=='valid':\n        x_vec = valid_x_vec\n        y_vec = valid_y_vec\n        example_df = valid_df\n    elif use_split=='train':\n        x_vec = train_x_vec\n        y_vec = train_y_vec\n        example_df = train_df\n    else:\n        raise ValueError('Unknown split: {}'.format(use_split))\n    \n    valid_pred = in_model.predict(x_vec)\n    fig, m_axs = plt.subplots(4, 2, figsize=(20, 40))\n    all_rows = []\n    ax1 = m_axs[0,0]\n    for i, c_allergen in enumerate(allergens):\n        tpr, fpr, _ = roc_curve(y_vec[:, i], valid_pred[:, i])\n        auc = roc_auc_score(y_vec[:, i], valid_pred[:, i])\n        acc = accuracy_score(y_vec[:, i], valid_pred[:, i]>0.5)\n        ax1.plot(tpr, fpr, '.-', label='{}: AUC {:0.2f}, Accuracy: {:2.0%}'.format(c_allergen, auc, acc))\n        all_rows+=[{'allegen': c_allergen, \n                    'prediction': valid_pred[j, i], \n                    'class': 'Positive' if y_vec[j, i]>0.5 else 'Negative'} \n                         for j in range(valid_pred.shape[0])]\n    \n    d_ax = m_axs[0, 1]\n    t_yp = np.mean(valid_pred, 0)\n    t_y = np.mean(y_vec, 0)\n    d_ax.barh(np.arange(len(allergens))+0.1, t_yp, alpha=0.5, label='Predicted')\n    d_ax.barh(np.arange(len(allergens))-0.1, t_y+0.001, alpha=0.5, label='Ground Truth')\n    d_ax.set_xlim(0, 1)\n    d_ax.set_yticks(range(len(allergens)))\n    d_ax.set_yticklabels(allergens, rotation=0)\n    d_ax.set_title('Overall')\n    d_ax.legend()\n    \n    # show example images\n    ax1.legend()\n    for (_, c_row), (c_ax, d_ax) in zip(\n        example_df.sample(m_axs.shape[0]).iterrows(), \n                               m_axs[1:]):\n        \n        c_ax.imshow(imread(c_row['image_path']))\n        c_ax.set_title(c_row['title'])\n        c_ax.axis('off')\n        t_yp = in_model.predict(np.expand_dims(c_row['color_features'], 0))\n        t_y = np.array(c_row['allergy_vec'])\n        d_ax.barh(np.arange(len(allergens))+0.1, t_yp[0], alpha=0.5, label='Predicted')\n        d_ax.barh(np.arange(len(allergens))-0.1, t_y+0.001, alpha=0.5, label='Ground Truth')\n        d_ax.set_yticks(range(len(allergens)))\n        d_ax.set_yticklabels(allergens, rotation=0)\n        d_ax.set_xlim(0, 1)\n        d_ax.legend();\n    \n    # nice dataframe of output\n    c_all_df = pd.DataFrame(all_rows)\n    fig, ax1 = plt.subplots(1, 1, figsize=(12, 5))\n    if plot_type=='swarm':\n        sns.swarmplot(data=c_all_df, hue='class', y='prediction', x='allegen', size=2.0, ax=ax1)\n    elif plot_type=='box':\n        sns.boxplot(data=c_all_df, hue='class', y='prediction', x='allegen', ax=ax1)\n    ax1.set_ylim(-0.05, 1.05)\n    return c_all_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The Simplist Model\nNearest Neighbor works by finding the most similar case from the training data using the feature vector. We can directly visualize this by showing which training image was being looked at.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nknn = KNeighborsRegressor(n_neighbors=1)\nknn.fit(train_x_vec, train_y_vec)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Show the results\nWe get incredibly good, nearly perfect results! Are we done now? Time to build an app and sell it to google for $$$?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"show_model_results(knn, use_split='train', plot_type='box');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's dig down a bit deeper, how does it work?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, m_axs = plt.subplots(6, 4, figsize=(30, 40))\ndummy_web_image = Image.new(size=(1,1), mode='RGB').convert('P', palette='web')\n\nfor (c_ax, c_feat_ax, d_ax, d_feat_ax), (_, c_row) in zip(m_axs, \n                            alleg_df.sample(m_axs.shape[0], random_state=2018).iterrows()):\n    \n    query_img = Image.open(c_row['image_path'])\n    idx_to_color = np.array(query_img.convert('P', palette='web').getpalette()).reshape((-1, 3))/255.0\n    c_ax.imshow(query_img)\n    c_ax.set_title(c_row['title'][:25])\n    c_ax.axis('off')\n    counts, bins = np.histogram(np.ravel(query_img.convert('P', palette='web')), \n                                bins=np.arange(256))\n    \n    for i in range(counts.shape[0]):\n        c_feat_ax.bar(bins[i], counts[i], color=idx_to_color[i], edgecolor='k', linewidth=0.1)\n    c_feat_ax.set_yscale('log')\n    c_feat_ax.set_xlabel('Color Id')\n    c_feat_ax.set_ylabel('Pixel Count')\n    c_feat_ax.set_title('Feature Vector')\n    \n    dist, idx = knn.kneighbors(np.expand_dims(c_row['color_features'], 0))\n    m_row = train_df.iloc[idx[0][0]]\n    matched_img = Image.open(m_row['image_path'])\n    \n    d_ax.imshow(matched_img)\n    d_ax.set_title('Closest Match\\n{}\\nDistance: {:2.1%}'.format(m_row['title'][:25], dist[0][0]))\n    d_ax.axis('off')\n    \n    counts, bins = np.histogram(np.ravel(matched_img.convert('P', palette='web')), \n                                bins=np.arange(256))\n    \n    for i in range(counts.shape[0]):\n        d_feat_ax.bar(bins[i], counts[i], color=idx_to_color[i], edgecolor='k', linewidth=0.1)\n    d_feat_ax.set_yscale('log')\n    d_feat_ax.set_xlabel('Color Id')\n    d_feat_ax.set_ylabel('Pixel Count')\n    c_feat_ax.set_title('Matched Feature')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Use on the validation split","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"show_model_results(knn, use_split='valid');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Linear Regression Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlr = LinearRegression()\nlr.fit(train_x_vec, train_y_vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_model_results(lr);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Normalize the input\n\nWe can make a pipeline to normalize the input and remove bad features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.feature_selection import VarianceThreshold\nlr_pipe = make_pipeline(RobustScaler(), VarianceThreshold(0.99), LinearRegression())\nlr_pipe.fit(train_x_vec, train_y_vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_model_results(lr_pipe);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# More Complicated Models\nWe can try decision trees to get better results","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.decomposition import PCA\ndt_pipe = make_pipeline(RobustScaler(), \n                        PCA(n_components=10), \n                        DecisionTreeRegressor(max_depth=5, min_samples_split=50))\ndt_pipe.fit(train_x_vec, train_y_vec)\nshow_model_results(dt_pipe);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import export_graphviz\nimport graphviz\ndef show_tree(in_tree):\n    return graphviz.Source(export_graphviz(in_tree, out_file=None))\n\nshow_tree(dt_pipe.steps[-1][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fancier Models\nHere we can use much fancier models like random forest to even further improve the performance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrf_pipe = make_pipeline(RobustScaler(), RandomForestRegressor(n_estimators=200))\nrf_pipe.fit(train_x_vec, train_y_vec)\nshow_model_results(rf_pipe);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## XGBoost\nOne of the most powerful classification tools","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\nfrom sklearn.multioutput import MultiOutputRegressor\nxg_pipe = make_pipeline(RobustScaler(), \n                        MultiOutputRegressor(XGBRegressor(objective='reg:linear')))\nxg_pipe.fit(train_x_vec, train_y_vec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_model_results(xg_pipe);","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}